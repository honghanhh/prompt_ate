{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c378bcae-47b1-4b11-9359-ab9e3364e138",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d2e379c-9c21-46e1-b6f1-ac91affca0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(df, col):\n",
    "    res = [re.sub('\\n','', str(x)) for x in df[col]]\n",
    "    res =  [x.split('                ')[0] for x in res]\n",
    "    res =  [x.split('Note')[0] for x in res]\n",
    "    res =  ['' if x[1:4] == '\"\"\"' else x for x in res]\n",
    "    return res\n",
    "\n",
    "def extract_between_markers(input_string):\n",
    "    pattern = r'@@(.*?)##'\n",
    "    extracted = re.findall(pattern, input_string)\n",
    "    return extracted\n",
    "\n",
    "\n",
    "def computeTermEvalMetrics(extracted_terms, gold_df):\n",
    "    # make lower case cause gold standard is lower case\n",
    "    extracted_terms = [item.lower() for item in extracted_terms]\n",
    "    extracted_terms = set([x for x in extracted_terms if x != ''])\n",
    "    gold_set = [item.lower() for item in gold_df]\n",
    "    gold_set =  set([x for x in gold_set if x != ''])\n",
    "    true_pos = extracted_terms.intersection(gold_set)\n",
    "    recall = round(len(true_pos)*100/len(gold_set),1)\n",
    "    precision = round(len(true_pos)*100/len(extracted_terms),1)\n",
    "    fscore = round(2*(precision*recall)/(precision+recall),1)\n",
    "    print(str(precision)+' & ' +  str(recall)+' & ' +  str(fscore))\n",
    "    return precision, recall, fscore\n",
    "\n",
    "def eval_template3(df, col, gold_path):\n",
    "    output =  postprocess(df, col)\n",
    "    output = [extract_between_markers(x) for x in output] \n",
    "    predictions = []\n",
    "    for x in output:\n",
    "        predictions.extend(x)\n",
    "\n",
    "    gold_list = pd.read_csv(gold_path, header=None, delimiter='\\t')[0].tolist()\n",
    "    computeTermEvalMetrics(predictions, gold_list)\n",
    "\n",
    "def extract_entities(words, labels):\n",
    "    entities = []\n",
    "    current_entity = ''\n",
    "    current_label = ''\n",
    "\n",
    "    for word, label in zip(words, labels):\n",
    "        if label.startswith('B'):\n",
    "            if current_entity:\n",
    "                entities.append(current_entity.strip())\n",
    "            current_entity = word\n",
    "            current_label = label[2:]\n",
    "        elif label.startswith('I') and current_label == label[2:]:\n",
    "            current_entity += ' ' + word\n",
    "        else:\n",
    "            if current_entity:\n",
    "                entities.append(current_entity.strip())\n",
    "                current_entity = ''\n",
    "                current_label = ''\n",
    "\n",
    "    if current_entity:\n",
    "        entities.append(current_entity.strip())\n",
    "\n",
    "    return entities\n",
    "\n",
    "\n",
    "def filter_text(text):\n",
    "    allowed_chars = {'B', 'I', 'O', ' '}\n",
    "    filtered_text = ''.join(c for c in text if c in allowed_chars)\n",
    "    return filtered_text\n",
    "\n",
    "def eval_template1(df, col, gold_list):\n",
    "    output = postprocess(df, col)\n",
    "    output = [re.sub(\"'\", \"\", x).strip() for x in output]\n",
    "    \n",
    "    extracted_list = []\n",
    "    for x, y in list(zip(df.words, output)):\n",
    "        words = eval(x)\n",
    "        labels = y[:len(words)*2]\n",
    "        \n",
    "        if labels.startswith(\"'I\") or labels == '':\n",
    "            labels = 'O '*len(words)\n",
    "        labels =  filter_text(labels).split(' ')\n",
    "        extracted_list.append(labels)\n",
    "\n",
    "    predictions = []\n",
    "    for x, y in zip(df.words, extracted_list):\n",
    "        terms =  extract_entities(eval(x), y)\n",
    "        predictions.extend(terms)\n",
    "    precision, recall, fscore = computeTermEvalMetrics(predictions, gold_list)\n",
    "    return precision, recall, fscore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea95efd0-b877-4594-8623-81f809a5fbbf",
   "metadata": {},
   "source": [
    "## LLAMA 7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49e7d93e-0bcd-49c9-94b3-582a5139c138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_prompts(df, format, lang, ver, gold_list):\n",
    "    if  \"1\" in format:\n",
    "        print(\"#\"*50)\n",
    "        print(\"#1. Extracted IOB format\")\n",
    "        precision, recall, fscore = eval_template1(df, format, gold_list)\n",
    "\n",
    "    elif \"2\" in format:\n",
    "        print(\"#\"*50)\n",
    "        print(\"#2. Extracted candidate term list\")\n",
    "        candidate_terms = []\n",
    "        for x in df[format]:\n",
    "            ## 13B ANN\n",
    "            if \"[global, proteomics, pathway, analysis, pressure-overload-induced, heart, failure, mitochondrial-targeted, peptides]\" in str(x):\n",
    "                candidate_terms.extend([\"global\", \"proteomics\", \"pathway\", \"analysis\", \"pressure-overload-induced\", \"heart\", \"failure\", \"mitochondrial-targeted\", \"peptides\"])\n",
    "            ## 13B NES    \n",
    "            elif '[ \"diuretics\", \"comorbidities\", \"6-MWT\", \"NYHA class III\", \"age > 65 years\" ]' in str(x):\n",
    "                candidate_terms.extend([ \"diuretics\", \"comorbidities\", \"6-MWT\", \"NYHA class III\", \"age > 65 years\" ])\n",
    "            elif '[\"patient-level regression\", \"30-day risk-adjusted mortality\", \"readmissions\", \"costs\", \"volume groups\", \"patient\", \"physician\", \"hospital characteristics\"]' in str(x):\n",
    "                candidate_terms.extend([\"patient-level regression\", \"30-day risk-adjusted mortality\", \"readmissions\", \"costs\", \"volume groups\", \"patient\", \"physician\", \"hospital characteristics\"])\n",
    "            else:\n",
    "                term = eval(str(x).split('Output: ')[1].split('[INST')[0].strip()) if len(str(x).split('Output: ')) > 1 and len(str(x).split('Output: ')[1].split('[INST')[0].strip()) > 1 else []\n",
    "                candidate_terms.extend(term)\n",
    "        precision, recall, fscore = computeTermEvalMetrics(candidate_terms, gold_list)\n",
    "    elif \"3\" in format:\n",
    "        print(\"#\"*50)\n",
    "        print(\"#3. Masking terms\")\n",
    "        ### RAW\n",
    "        candidate_terms = []\n",
    "        for x in df[format]:\n",
    "            sent = str(x).split('Output: ')[1].split('[INST]')[0].strip() if len(str(x).split('Output: ')) > 1 else \"\"\n",
    "            candidate_terms.extend(extract_between_markers(sent))\n",
    "\n",
    "        ### PROCESSED\n",
    "        candidate_terms_list = []\n",
    "        for x in candidate_terms:\n",
    "            candidate_terms_list.append(x.split('@@')[-1])\n",
    "\n",
    "        precision, recall, fscore = computeTermEvalMetrics(candidate_terms_list, gold_list)\n",
    "    else:\n",
    "        raise Exception(\"Format not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fb36d4d-2876-40e3-b917-1aee87a8fe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_directory = '../results/llama2_results/llama_en_htfl_7b'\n",
    "\n",
    "llama_en_htfl_7b_ann_tem1 = pd.read_csv(os.path.join(csv_directory,'llama_en_htfl_7b_ann_tem1.csv'))\n",
    "llama_en_htfl_7b_ann_tem2 = pd.read_csv(os.path.join(csv_directory,'llama_en_htfl_7b_ann_tem2.csv'))\n",
    "llama_en_htfl_7b_ann_tem3 = pd.read_csv(os.path.join(csv_directory,'llama_en_htfl_7b_ann_tem3.csv'))\n",
    "\n",
    "llama_en_htfl_7b_nes_tem1 = pd.read_csv(os.path.join(csv_directory,'llama_en_htfl_7b_nes_tem1.csv'))\n",
    "llama_en_htfl_7b_nes_tem2 = pd.read_csv(os.path.join(csv_directory,'llama_en_htfl_7b_nes_tem2.csv'))\n",
    "llama_en_htfl_7b_nes_tem3 = pd.read_csv(os.path.join(csv_directory,'llama_en_htfl_7b_nes_tem3.csv'))\n",
    "\n",
    "llama_fr_htfl_7b_ann_tem1 = pd.read_csv(os.path.join(csv_directory,'llama_fr_htfl_7b_ann_tem1.csv'))\n",
    "llama_fr_htfl_7b_ann_tem2 = pd.read_csv(os.path.join(csv_directory,'llama_fr_htfl_7b_ann_tem2.csv'))\n",
    "llama_fr_htfl_7b_ann_tem3 = pd.read_csv(os.path.join(csv_directory,'llama_fr_htfl_7b_ann_tem3.csv'))\n",
    "\n",
    "llama_fr_htfl_7b_nes_tem1 = pd.read_csv(os.path.join(csv_directory,'llama_fr_htfl_7b_nes_tem1.csv'))\n",
    "llama_fr_htfl_7b_nes_tem2 = pd.read_csv(os.path.join(csv_directory,'llama_fr_htfl_7b_nes_tem2.csv'))\n",
    "llama_fr_htfl_7b_nes_tem3 = pd.read_csv(os.path.join(csv_directory,'llama_fr_htfl_7b_nes_tem3.csv'))\n",
    "\n",
    "llama_nl_htfl_7b_ann_tem1 = pd.read_csv(os.path.join(csv_directory,'llama_nl_htfl_7b_ann_tem1.csv'))\n",
    "llama_nl_htfl_7b_ann_tem2 = pd.read_csv(os.path.join(csv_directory,'llama_nl_htfl_7b_ann_tem2.csv'))\n",
    "llama_nl_htfl_7b_ann_tem3 = pd.read_csv(os.path.join(csv_directory,'llama_nl_htfl_7b_ann_tem3.csv'))\n",
    "\n",
    "llama_nl_htfl_7b_nes_tem1 = pd.read_csv(os.path.join(csv_directory,'llama_nl_htfl_7b_nes_tem1.csv'))\n",
    "llama_nl_htfl_7b_nes_tem2 = pd.read_csv(os.path.join(csv_directory,'llama_nl_htfl_7b_nes_tem2.csv'))\n",
    "llama_nl_htfl_7b_nes_tem3 = pd.read_csv(os.path.join(csv_directory,'llama_nl_htfl_7b_nes_tem3.csv'))\n",
    "\n",
    "gold_en_ann =  pd.read_csv('htfl_en_terms.tsv', header=None, delimiter='\\t')[0].tolist()\n",
    "gold_en_nes =  pd.read_csv('htfl_en_terms_nes.tsv', header=None, delimiter='\\t')[0].tolist()\n",
    "\n",
    "gold_fr_ann =  pd.read_csv('htfl_fr_terms.tsv', header=None, delimiter='\\t')[0].tolist()\n",
    "gold_fr_nes =  pd.read_csv('htfl_fr_terms_nes.tsv', header=None, delimiter='\\t')[0].tolist()\n",
    "\n",
    "gold_nl_ann =  pd.read_csv('htfl_nl_terms.tsv', header=None, delimiter='\\t')[0].tolist()\n",
    "gold_nl_nes =  pd.read_csv('htfl_nl_terms_nes.tsv', header=None, delimiter='\\t')[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "139f9da8-4d7a-4d9a-bdc9-1ac4185e0550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "#1. Extracted IOB format\n",
      "12.4 & 4.8 & 6.9\n",
      "##################################################\n",
      "#2. Extracted candidate term list\n",
      "40.4 & 62.6 & 49.1\n",
      "##################################################\n",
      "#3. Masking terms\n",
      "40.3 & 26.8 & 32.2\n",
      "##################################################\n",
      "#1. Extracted IOB format\n",
      "17.3 & 7.3 & 10.3\n",
      "##################################################\n",
      "#2. Extracted candidate term list\n",
      "42.9 & 63.4 & 51.2\n",
      "##################################################\n",
      "#3. Masking terms\n",
      "45.0 & 32.5 & 37.7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "evaluate_prompts(llama_en_htfl_7b_ann_tem2, 'llama_output2ann', 'en', 'ann', gold_en_ann)\n",
    "evaluate_prompts(llama_en_htfl_7b_ann_tem3, 'llama_output3ann', 'en', 'ann', gold_en_ann)\n",
    "evaluate_prompts(llama_en_htfl_7b_nes_tem1, 'llama_output1nes', 'en', 'nes', gold_en_nes)\n",
    "evaluate_prompts(llama_en_htfl_7b_nes_tem2, 'llama_output2nes', 'en', 'nes', gold_en_nes)\n",
    "evaluate_prompts(llama_en_htfl_7b_nes_tem3, 'llama_output3nes', 'en', 'nes', gold_en_nes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ff1475d-64b4-44b0-9565-bf5fc333b855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "#1. Extracted IOB format\n",
      "7.5 & 9.3 & 8.3\n",
      "##################################################\n",
      "#2. Extracted candidate term list\n",
      "36.3 & 59.2 & 45.0\n",
      "##################################################\n",
      "#3. Masking terms\n",
      "58.5 & 23.4 & 33.4\n",
      "##################################################\n",
      "#1. Extracted IOB format\n",
      "8.4 & 11.0 & 9.5\n",
      "##################################################\n",
      "#2. Extracted candidate term list\n",
      "36.0 & 61.6 & 45.4\n",
      "##################################################\n",
      "#3. Masking terms\n",
      "52.1 & 34.5 & 41.5\n"
     ]
    }
   ],
   "source": [
    "evaluate_prompts(llama_fr_htfl_7b_ann_tem1, 'llama_output1ann', 'fr', 'ann', gold_fr_ann)\n",
    "evaluate_prompts(llama_fr_htfl_7b_ann_tem2, 'llama_output2ann', 'fr', 'ann', gold_fr_ann)\n",
    "evaluate_prompts(llama_fr_htfl_7b_ann_tem3, 'llama_output3ann', 'fr', 'ann', gold_fr_ann)\n",
    "evaluate_prompts(llama_fr_htfl_7b_nes_tem1, 'llama_output1nes', 'fr', 'nes', gold_fr_nes)\n",
    "evaluate_prompts(llama_fr_htfl_7b_nes_tem2, 'llama_output2nes', 'fr', 'nes', gold_fr_nes)\n",
    "evaluate_prompts(llama_fr_htfl_7b_nes_tem3, 'llama_output3nes', 'fr', 'nes', gold_fr_nes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a321e76c-a445-48a4-878e-58c47d4c09ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "#1. Extracted IOB format\n",
      "19.2 & 14.4 & 16.5\n",
      "##################################################\n",
      "#2. Extracted candidate term list\n",
      "40.4 & 73.1 & 52.0\n",
      "##################################################\n",
      "#3. Masking terms\n",
      "53.8 & 41.6 & 46.9\n",
      "##################################################\n",
      "#1. Extracted IOB format\n",
      "16.6 & 23.8 & 19.6\n",
      "##################################################\n",
      "#2. Extracted candidate term list\n",
      "40.3 & 75.6 & 52.6\n",
      "##################################################\n",
      "#3. Masking terms\n",
      "48.8 & 52.3 & 50.5\n"
     ]
    }
   ],
   "source": [
    "evaluate_prompts(llama_nl_htfl_7b_ann_tem1, 'llama_output1ann', 'nl', 'ann', gold_nl_ann)\n",
    "evaluate_prompts(llama_nl_htfl_7b_ann_tem2, 'llama_output2ann', 'nl', 'ann', gold_nl_ann)\n",
    "evaluate_prompts(llama_nl_htfl_7b_ann_tem3, 'llama_output3ann', 'nl', 'ann', gold_nl_ann)\n",
    "evaluate_prompts(llama_nl_htfl_7b_nes_tem1, 'llama_output1nes', 'nl', 'nes', gold_nl_nes)\n",
    "evaluate_prompts(llama_nl_htfl_7b_nes_tem2, 'llama_output2nes', 'nl', 'nes', gold_nl_nes)\n",
    "llama_nl_htfl_7b_nes_tem3['llama_output3nes'] = llama_nl_htfl_7b_nes_tem3['llama_output1nes'].copy()\n",
    "evaluate_prompts(llama_nl_htfl_7b_nes_tem3, 'llama_output3nes', 'nl', 'nes', gold_nl_nes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0332d0ae-5e3f-4026-9f66-4d1329a27858",
   "metadata": {},
   "source": [
    "## LLAMA 13B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd7a54d0-33b7-47f6-b420-b77ef3a25d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../results/llama2_results/llama_en_htfl_13b'\n",
    "\n",
    "llama_en_htfl_13b_ann_tem1 = pd.read_csv(os.path.join(directory,'llama_en_htfl_13b_ann_tem1.csv'))\n",
    "llama_en_htfl_13b_ann_tem2 = pd.read_csv(os.path.join(directory,'llama_en_htfl_13b_ann_tem2.csv'))\n",
    "llama_en_htfl_13b_ann_tem3 = pd.read_csv(os.path.join(directory,'llama_en_htfl_13b_ann_tem3.csv'))\n",
    "\n",
    "llama_en_htfl_13b_nes_tem1 = pd.read_csv(os.path.join(directory,'llama_en_htfl_13b_nes_tem1.csv'))\n",
    "llama_en_htfl_13b_nes_tem2 = pd.read_csv(os.path.join(directory,'llama_en_htfl_13b_nes_tem2.csv'))\n",
    "llama_en_htfl_13b_nes_tem3 = pd.read_csv(os.path.join(directory,'llama_en_htfl_13b_nes_tem3.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "983e8505-3162-4a46-829a-42363adca80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "#1. Extracted IOB format\n",
      "12.1 & 1.7 & 3.0\n",
      "##################################################\n",
      "#2. Extracted candidate term list\n",
      "35.0 & 63.4 & 45.1\n",
      "##################################################\n",
      "#3. Masking terms\n",
      "40.0 & 36.9 & 38.4\n",
      "##################################################\n",
      "#1. Extracted IOB format\n",
      "25.9 & 2.4 & 4.4\n",
      "##################################################\n",
      "#2. Extracted candidate term list\n",
      "38.4 & 66.1 & 48.6\n",
      "##################################################\n",
      "#3. Masking terms\n",
      "40.3 & 47.5 & 43.6\n"
     ]
    }
   ],
   "source": [
    "evaluate_prompts(llama_en_htfl_13b_ann_tem1, 'llama_output1ann', 'en', 'ann', gold_en_ann)\n",
    "evaluate_prompts(llama_en_htfl_13b_ann_tem2, 'llama_output2ann', 'en', 'ann', gold_en_ann)\n",
    "evaluate_prompts(llama_en_htfl_13b_ann_tem3, 'llama_output3ann', 'en', 'ann', gold_en_ann)\n",
    "evaluate_prompts(llama_en_htfl_13b_nes_tem1, 'llama_output1nes', 'en', 'nes', gold_en_nes)\n",
    "evaluate_prompts(llama_en_htfl_13b_nes_tem2, 'llama_output2nes', 'en', 'nes', gold_en_nes)\n",
    "evaluate_prompts(llama_en_htfl_13b_nes_tem3, 'llama_output3nes', 'en', 'nes', gold_en_nes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd66d48-e039-4734-a574-8a2414b84d76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
